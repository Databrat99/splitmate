import duckdb

# Connect to an in-memory DuckDB database
con = duckdb.connect()

# Read and preview the CSV file
df = con.execute("SELECT * FROM 'your_file.csv'").fetchdf()

# Optional: See the first few rows
print(df.head())

CREATE TABLE my_table AS SELECT * FROM 'your_file.csv';
SELECT COUNT(*) FROM my_table;


import pandas as pd

# Read in chunks to avoid memory issues
chunk_size = 100000  # adjust based on your RAM
chunks = pd.read_csv('your_file.csv', chunksize=chunk_size)

for chunk in chunks:
    print(chunk.head())  # process each chunk


import dask.dataframe as dd
df = dd.read_csv('your_file.csv')
print(df.head())
